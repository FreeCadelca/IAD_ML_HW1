{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffq6A2-ifzAA"
   },
   "source": [
    "# Интеллектуальный анализ данных – весна 2025\n",
    "# Домашнее задание 6: классификация текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Правила:\n",
    "\n",
    "\n",
    "\n",
    "*   Домашнее задание оценивается в 10 баллов.\n",
    "*   Можно использовать без доказательства любые результаты, встречавшиеся на лекциях или семинарах по курсу, если получение этих результатов не является вопросом задания.\n",
    "*  Можно использовать любые свободные источники с *обязательным* указанием ссылки на них.\n",
    "*  Плагиат не допускается. При обнаружении случаев списывания, 0 за работу выставляется всем участникам нарушения, даже если можно установить, кто у кого списал.\n",
    "*  Старайтесь сделать код как можно более оптимальным. В частности, будет штрафоваться использование циклов в тех случаях, когда операцию можно совершить при помощи инструментов библиотек, о которых рассказывалось в курсе.\n",
    "* Если в задании есть вопрос на рассуждение, то за отсутствие ответа на него балл за задание будет снижен вполовину."
   ],
   "metadata": {
    "id": "EPcxtekTA1Sm"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itRtFtrOf0_b"
   },
   "source": [
    "В этом домашнем задании вам предстоит построить классификатор текстов.\n",
    "\n",
    "Будем предсказывать эмоциональную окраску твиттов о коронавирусе.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tNGRVO7_g9mz",
    "ExecuteTime": {
     "end_time": "2025-05-10T10:16:12.192420600Z",
     "start_time": "2025-05-10T10:16:12.172603200Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zOy8iHJQg_Ss",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "outputId": "6a32c325-1b9a-4895-ab22-5e985016da91",
    "ExecuteTime": {
     "end_time": "2025-05-10T10:16:12.367420200Z",
     "start_time": "2025-05-10T10:16:12.179419600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       UserName  ScreenName       Location     TweetAt  \\\n6407      11581       56533            NaN  19-03-2020   \n4214       8921       53873         Russia  18-03-2020   \n28513     38782       83734  Covington, LA  08-04-2020   \n22951     31838       76790          India  04-04-2020   \n\n                                           OriginalTweet           Sentiment  \n6407   Our communities are facing the most challengin...            Negative  \n4214   If you think #COVID2019, the Wall-Street under...  Extremely Negative  \n28513  A few bright spots are emerging amid the chall...            Positive  \n22951  APNA is taking small initiatives,which are to ...  Extremely Positive  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6407</th>\n      <td>11581</td>\n      <td>56533</td>\n      <td>NaN</td>\n      <td>19-03-2020</td>\n      <td>Our communities are facing the most challengin...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>4214</th>\n      <td>8921</td>\n      <td>53873</td>\n      <td>Russia</td>\n      <td>18-03-2020</td>\n      <td>If you think #COVID2019, the Wall-Street under...</td>\n      <td>Extremely Negative</td>\n    </tr>\n    <tr>\n      <th>28513</th>\n      <td>38782</td>\n      <td>83734</td>\n      <td>Covington, LA</td>\n      <td>08-04-2020</td>\n      <td>A few bright spots are emerging amid the chall...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>22951</th>\n      <td>31838</td>\n      <td>76790</td>\n      <td>India</td>\n      <td>04-04-2020</td>\n      <td>APNA is taking small initiatives,which are to ...</td>\n      <td>Extremely Positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tweets_coronavirus.csv', encoding='latin-1')\n",
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2OiDog9ZBlS"
   },
   "source": [
    "Для каждого твитта указано:\n",
    "\n",
    "\n",
    "*   UserName - имя пользователя, заменено на целое число для анонимности\n",
    "*   ScreenName - отображающееся имя пользователя, заменено на целое число для анонимности\n",
    "*   Location - местоположение\n",
    "*   TweetAt - дата создания твитта\n",
    "*   OriginalTweet - текст твитта\n",
    "*   Sentiment - эмоциональная окраска твитта (целевая переменная)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZTMseDkhTC7"
   },
   "source": [
    "## Задание 1 Подготовка (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx2-odn9hdAW"
   },
   "source": [
    "Целевая переменная находится в колонке `Sentiment`.  Преобразуйте ее таким образом, чтобы она стала бинарной: 1 - если у твитта положительная или очень положительная эмоциональная окраска и 0 - если отрицательная или очень отрицательная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZaQKQ1zEjP15",
    "ExecuteTime": {
     "end_time": "2025-05-10T10:16:12.394419400Z",
     "start_time": "2025-05-10T10:16:12.317059100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       UserName  ScreenName          Location     TweetAt  \\\n26822     36685       81637         Worldwide  07-04-2020   \n1054       5076       50028  Selangor , MY  ?  17-03-2020   \n22533     31338       76290               NaN  03-04-2020   \n975        4980       49932               NaN  17-03-2020   \n\n                                           OriginalTweet  Sentiment  \n26822  Los Angeles County asks not to go to the super...          0  \n1054   Keep yourself safe at home during this covid-1...          1  \n22533  Share prices in the Securities Exchange were i...          1  \n975    If you are one of the people that has an essen...          1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26822</th>\n      <td>36685</td>\n      <td>81637</td>\n      <td>Worldwide</td>\n      <td>07-04-2020</td>\n      <td>Los Angeles County asks not to go to the super...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1054</th>\n      <td>5076</td>\n      <td>50028</td>\n      <td>Selangor , MY  ?</td>\n      <td>17-03-2020</td>\n      <td>Keep yourself safe at home during this covid-1...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22533</th>\n      <td>31338</td>\n      <td>76290</td>\n      <td>NaN</td>\n      <td>03-04-2020</td>\n      <td>Share prices in the Securities Exchange were i...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>975</th>\n      <td>4980</td>\n      <td>49932</td>\n      <td>NaN</td>\n      <td>17-03-2020</td>\n      <td>If you are one of the people that has an essen...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'] = df['Sentiment'].apply(lambda x: 1 if x in ('Positive', 'Extremely Positive') else 0)\n",
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGq1FxJ-kBo5"
   },
   "source": [
    "Сбалансированы ли классы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "a7gdNtxckK5V",
    "ExecuteTime": {
     "end_time": "2025-05-10T10:16:12.471931400Z",
     "start_time": "2025-05-10T10:16:12.338950400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "1    18046\n",
      "0    15398\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ng8BCelMkWb0"
   },
   "source": [
    "**Ответ:** Классы сбалансированы достаточно, но не идеально"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmSIBSsLk5Zz"
   },
   "source": [
    "Выведете на экран информацию о пропусках в данных. Если пропуски присутствуют заполните их строкой 'Unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UhUVRkR5kxa7",
    "ExecuteTime": {
     "end_time": "2025-05-10T10:16:12.539450700Z",
     "start_time": "2025-05-10T10:16:12.341931100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in columns before fill:\n",
      "UserName 0\n",
      "ScreenName 0\n",
      "Location 7049\n",
      "TweetAt 0\n",
      "OriginalTweet 0\n",
      "Sentiment 0\n",
      "Missing data in columns after fill:\n",
      "UserName 0\n",
      "ScreenName 0\n",
      "Location 0\n",
      "TweetAt 0\n",
      "OriginalTweet 0\n",
      "Sentiment 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dmitriy\\AppData\\Local\\Temp\\ipykernel_12104\\2872222514.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[i].fillna(\"Unknown\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing data in columns before fill:\")\n",
    "for i in df.head():\n",
    "    print(i, df[i].isna().sum())\n",
    "for i in df.head():\n",
    "    df[i].fillna(\"Unknown\", inplace=True)\n",
    "print(\"Missing data in columns after fill:\")\n",
    "for i in df.head():\n",
    "    print(i, df[i].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tzt27tfjUpq"
   },
   "source": [
    "Разделите данные на обучающие и тестовые в соотношении 7 : 3 и укажите `random_state=0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xSLOA9tIj9Z6",
    "ExecuteTime": {
     "end_time": "2025-05-10T10:16:12.914706900Z",
     "start_time": "2025-05-10T10:16:12.359418900Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.3, stratify=df['Sentiment'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9RrPUsJlL60"
   },
   "source": [
    "## Задание 2 Токенизация (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Dz_b7Xopc_R"
   },
   "source": [
    "Постройте словарь на основе обучающей выборки и посчитайте количество встреч каждого токена с использованием самой простой токенизации - деления текстов по пробельным символам и приведения токенов в нижний регистр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SFr67WOJphny",
    "ExecuteTime": {
     "end_time": "2025-05-10T10:57:52.614350100Z",
     "start_time": "2025-05-10T10:57:52.345014100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    advice Talk to your neighbours family to excha...\n",
      "1    Coronavirus Australia: Woolworths to give elde...\n",
      "2    My food stock is not the only one which is emp...\n",
      "3    Me, ready to go at supermarket during the #COV...\n",
      "4    As news of the regionÃÂs first confirmed COV...\n",
      "Name: OriginalTweet, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": "              Word  Count\n0              the  38250\n1               to  33447\n2              and  20935\n3               of  18578\n4                a  16667\n...            ...    ...\n103195  @tartiicat      1\n103196    new/used      1\n103197        rift      1\n103198     $700.00      1\n103199      whethe      1\n\n[103200 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the</td>\n      <td>38250</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>to</td>\n      <td>33447</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>and</td>\n      <td>20935</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>of</td>\n      <td>18578</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a</td>\n      <td>16667</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>103195</th>\n      <td>@tartiicat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103196</th>\n      <td>new/used</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103197</th>\n      <td>rift</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103198</th>\n      <td>$700.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103199</th>\n      <td>whethe</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>103200 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "words = []\n",
    "print(df[\"OriginalTweet\"].head(5))\n",
    "\n",
    "for i in df[\"OriginalTweet\"]:\n",
    "    for word in i.split():\n",
    "        words.append(word.lower())\n",
    "\n",
    "words = Counter(words)\n",
    "words_count = words.most_common()\n",
    "words_count_df = pd.DataFrame(words_count, columns=['Word', 'Count'])\n",
    "\n",
    "words_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pe0h2Jqkpnao"
   },
   "source": [
    "Какой размер словаря получился?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Ответ:** Как мы видим, получилось 103200 строк, значит столько же различных токенов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d2G1Z-Qpqkd"
   },
   "source": [
    "Выведите 10 самых популярных токенов с количеством встреч каждого из них. Объясните, почему именно эти токены в топе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Impi32a_pssg",
    "ExecuteTime": {
     "end_time": "2025-05-10T11:27:44.646907600Z",
     "start_time": "2025-05-10T11:27:44.615213Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "           Word  Count\n0           the  38250\n1            to  33447\n2           and  20935\n3            of  18578\n4             a  16667\n5            in  16024\n6           for  12193\n7  #coronavirus  11759\n8            is  10596\n9           are   9958",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the</td>\n      <td>38250</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>to</td>\n      <td>33447</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>and</td>\n      <td>20935</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>of</td>\n      <td>18578</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a</td>\n      <td>16667</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>in</td>\n      <td>16024</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>for</td>\n      <td>12193</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>#coronavirus</td>\n      <td>11759</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>is</td>\n      <td>10596</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>are</td>\n      <td>9958</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtuJCD0ApuFd"
   },
   "source": [
    "**Ответ:** Логично, что артикли, предлоги и ```#coronavirus``` оказались в топе, потому что артикли и предлоги - сами по себе частые связки в тексте, а хештег - просто тематика всех текстов, логично, что такой хештег будет "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7DTQDkWsVYp"
   },
   "source": [
    "Удалите стоп-слова из словаря и выведите новый топ-10 токенов (и количество встреч) по популярности.  Что можно сказать  о нем?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "8csSAdgTsnFx",
    "ExecuteTime": {
     "end_time": "2025-05-10T12:25:01.046677200Z",
     "start_time": "2025-05-10T12:25:01.017967400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            Word  Count\n7   #coronavirus  11759\n16        prices   5625\n18          food   5409\n23       grocery   4882\n24   supermarket   4662\n25      covid-19   4504\n26        people   4488\n27         store   4486\n35      #covid19   3561\n39      consumer   3233",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>#coronavirus</td>\n      <td>11759</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>prices</td>\n      <td>5625</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>food</td>\n      <td>5409</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>grocery</td>\n      <td>4882</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>supermarket</td>\n      <td>4662</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>covid-19</td>\n      <td>4504</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>people</td>\n      <td>4488</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>store</td>\n      <td>4486</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>#covid19</td>\n      <td>3561</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>consumer</td>\n      <td>3233</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "stops = set(stopwords.words('english'))\n",
    "words_count_df_copy = words_count_df[~words_count_df[\"Word\"].isin(stops)]\n",
    "words_count_df_copy.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZH0x2Lzs-Dh"
   },
   "source": [
    "**Ответ:** Видим, что теперь токены очистились от мусора - артиклей, предлогов и местоимений, которые, логично, есть в каждом тексте, и токены отражают обычные хештеги или самые частые слова. Я вижу, что многие из них связаны с едой или пищевой промышленностью. Возможно, это произошло, потому что еда - главное в выживании во времена коронавируса, а также супермаркеты - неизбежное скопление людей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKSGRyI-uor0"
   },
   "source": [
    "Также выведите 20 самых непопулярных слов (если самых непопулярных слов больше, выведите любые 20 из них) Почему эти токены непопулярны, требуется ли как-то дополнительно работать с ними?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "moArbwfvun9t",
    "ExecuteTime": {
     "end_time": "2025-05-10T12:26:49.338772400Z",
     "start_time": "2025-05-10T12:26:49.305234900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                           Word  Count\n103180                bullion's      1\n103181              #safe-haven      1\n103182          $1,715.25/ounce      1\n103183                     dec.      1\n103184                $1,722.20      1\n103185                rs.46,215      1\n103186                     gms.      1\n103187  https://t.co/s8coy5vvgn      1\n103188                   home??      1\n103189  https://t.co/v8xdxhqeyn      1\n103190           @mrsilverscott      1\n103191                  delays.      1\n103192                rejecting      1\n103193            @kameronwilds      1\n103194            martinsville,      1\n103195               @tartiicat      1\n103196                 new/used      1\n103197                     rift      1\n103198                  $700.00      1\n103199                   whethe      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>103180</th>\n      <td>bullion's</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103181</th>\n      <td>#safe-haven</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103182</th>\n      <td>$1,715.25/ounce</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103183</th>\n      <td>dec.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103184</th>\n      <td>$1,722.20</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103185</th>\n      <td>rs.46,215</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103186</th>\n      <td>gms.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103187</th>\n      <td>https://t.co/s8coy5vvgn</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103188</th>\n      <td>home??</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103189</th>\n      <td>https://t.co/v8xdxhqeyn</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103190</th>\n      <td>@mrsilverscott</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103191</th>\n      <td>delays.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103192</th>\n      <td>rejecting</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103193</th>\n      <td>@kameronwilds</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103194</th>\n      <td>martinsville,</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103195</th>\n      <td>@tartiicat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103196</th>\n      <td>new/used</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103197</th>\n      <td>rift</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103198</th>\n      <td>$700.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103199</th>\n      <td>whethe</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count_df_copy.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRp3J1gQunlR"
   },
   "source": [
    "**Ответ:** Эти токены непопулярны, потому что содержат пунктуацию, ссылки, конкретные числа/цифры или непопулярные хештеги. Я считаю, что их нужно обработать, удалив пунктуацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wx9LQOSPzvjV"
   },
   "source": [
    "Теперь воспользуемся токенайзером получше - TweetTokenizer из библиотеки nltk. Примените его и посмотрите на топ-10 популярных слов. Чем он отличается от топа, который получался раньше? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "2G1UkyVxzvFY",
    "ExecuteTime": {
     "end_time": "2025-05-10T14:01:27.481120800Z",
     "start_time": "2025-05-10T14:01:23.922947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               Word  Count\n0               the  34781\n1                 .  34284\n2                to  32812\n3                 ,  25142\n4               and  20439\n...             ...    ...\n87328  martinsville      1\n87329    @TartiiCat      1\n87330          Rift      1\n87331        700.00      1\n87332        whethe      1\n\n[87333 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the</td>\n      <td>34781</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>.</td>\n      <td>34284</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>to</td>\n      <td>32812</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>,</td>\n      <td>25142</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and</td>\n      <td>20439</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>87328</th>\n      <td>martinsville</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87329</th>\n      <td>@TartiiCat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87330</th>\n      <td>Rift</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87331</th>\n      <td>700.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87332</th>\n      <td>whethe</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>87333 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "words = []\n",
    "\n",
    "for i in df[\"OriginalTweet\"]:\n",
    "    words += tokenizer.tokenize(i)\n",
    "\n",
    "words = Counter(words)\n",
    "words_count = words.most_common()\n",
    "words_count_df = pd.DataFrame(words_count, columns=['Word', 'Count'])\n",
    "\n",
    "words_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50eVUnJN1Zxl"
   },
   "source": [
    "**Ответ:** На удивление, сейчас токенайзер выдал даже более худшие результаты, чем \"рабоче-крестьянский\" метод с split, потому что наш новый токенайзер отделяет знаки пунктуации от основного текста, и, естественно, знаков пунктуации в топе много."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gqQgiMs11bs"
   },
   "source": [
    "Удалите из словаря стоп-слова и пунктуацию, посмотрите на новый топ-10 слов с количеством встреч, есть ли теперь в нем что-то не похожее на слова?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "0yHWdFrp0Mup",
    "ExecuteTime": {
     "end_time": "2025-05-10T14:13:30.158411300Z",
     "start_time": "2025-05-10T14:13:30.119482200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               Word  Count\n10                Â  10498\n11                  10361\n13     #coronavirus  10211\n14               19  10142\n18                I   7484\n...             ...    ...\n87328  martinsville      1\n87329    @TartiiCat      1\n87330          Rift      1\n87331        700.00      1\n87332        whethe      1\n\n[87110 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>Â</td>\n      <td>10498</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td></td>\n      <td>10361</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>#coronavirus</td>\n      <td>10211</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>19</td>\n      <td>10142</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>I</td>\n      <td>7484</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>87328</th>\n      <td>martinsville</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87329</th>\n      <td>@TartiiCat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87330</th>\n      <td>Rift</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87331</th>\n      <td>700.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87332</th>\n      <td>whethe</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>87110 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "punctuation_list = list(punctuation)\n",
    "words_count_df_copy = words_count_df[\n",
    "    ~words_count_df[\"Word\"].isin(punctuation_list) & ~words_count_df[\"Word\"].isin(stops)]\n",
    "words_count_df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZJqXELP_Yxy"
   },
   "source": [
    "**Ответ:** Да, после очистки от мусора можно видеть а-ля адекватный список топа слов. Однако все еще присутствует мусор - нечитаемые символы, возможно, служебные, возможно, смайлики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzXjMsSB_kXB"
   },
   "source": [
    "Скорее всего в некоторых топах были неотображаемые символы или отдельные буквы не латинского алфавита. Уберем их: удалите из словаря токены из одного символа, позиция которого в таблице Unicode 128 и более (`ord(x) >= 128`)\n",
    "\n",
    "Выведите топ-10 самых популярных и топ-20 непопулярных слов. Чем полученные топы отличаются от итоговых топов, полученных при использовании токенизации по пробелам? Что теперь лучше, а что хуже?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "1695hlkS_1-J",
    "ExecuteTime": {
     "end_time": "2025-05-10T15:46:21.414924200Z",
     "start_time": "2025-05-10T15:46:21.361377100Z"
    }
   },
   "outputs": [],
   "source": [
    "words_count_df_copy = words_count_df_copy[\n",
    "    (words_count_df_copy[\"Word\"].str.len() > 1) |\n",
    "    (words_count_df_copy[\"Word\"].apply(\n",
    "        lambda x: ord(x) if len(x) == 1 else 0\n",
    "    ) <= 127)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "            Word  Count\n13  #coronavirus  10211\n14            19  10142\n18             I   7484\n23        prices   6166\n24         COVID   5945\n26          food   5423\n29         store   5234\n33   supermarket   4803\n35       grocery   4350\n36        people   4300",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13</th>\n      <td>#coronavirus</td>\n      <td>10211</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>19</td>\n      <td>10142</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>I</td>\n      <td>7484</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>prices</td>\n      <td>6166</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>COVID</td>\n      <td>5945</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>food</td>\n      <td>5423</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>store</td>\n      <td>5234</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>supermarket</td>\n      <td>4803</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>grocery</td>\n      <td>4350</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>people</td>\n      <td>4300</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count_df_copy.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T15:46:25.208320Z",
     "start_time": "2025-05-10T15:46:25.190992500Z"
    }
   },
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                          Word  Count\n87313  https://t.co/qUQ8Y0uM6n      1\n87314             @MajangChien      1\n87315                bullion's      1\n87316              #safe-haven      1\n87317                    1,715      1\n87318                    1,722      1\n87319                   46,215      1\n87320                      gms      1\n87321  https://t.co/S8coY5VVgN      1\n87322  https://t.co/v8XDXhqeYN      1\n87323                 roulette      1\n87324           @MrSilverScott      1\n87325                rejecting      1\n87326                      TAT      1\n87327            @KameronWilds      1\n87328             martinsville      1\n87329               @TartiiCat      1\n87330                     Rift      1\n87331                   700.00      1\n87332                   whethe      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>87313</th>\n      <td>https://t.co/qUQ8Y0uM6n</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87314</th>\n      <td>@MajangChien</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87315</th>\n      <td>bullion's</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87316</th>\n      <td>#safe-haven</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87317</th>\n      <td>1,715</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87318</th>\n      <td>1,722</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87319</th>\n      <td>46,215</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87320</th>\n      <td>gms</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87321</th>\n      <td>https://t.co/S8coY5VVgN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87322</th>\n      <td>https://t.co/v8XDXhqeYN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87323</th>\n      <td>roulette</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87324</th>\n      <td>@MrSilverScott</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87325</th>\n      <td>rejecting</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87326</th>\n      <td>TAT</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87327</th>\n      <td>@KameronWilds</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87328</th>\n      <td>martinsville</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87329</th>\n      <td>@TartiiCat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87330</th>\n      <td>Rift</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87331</th>\n      <td>700.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87332</th>\n      <td>whethe</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count_df_copy.tail(20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-10T15:49:03.224172800Z",
     "start_time": "2025-05-10T15:49:03.187193Z"
    }
   },
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzjHAKIlDvc6"
   },
   "source": [
    "**Ответ:** Теперь топ похож на реальный, немного отличается от нашего прошлого способа (в том числе, потому что мы не приводили слова к нижнему регистру). Из плюсов: разделения стали лучше, потому что не учитывается пунктуация и маленькие различия между словами, из минусов: появились местоимения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcDf9_6HB2zm"
   },
   "source": [
    "Выведите топ-10 популярных хештегов (токены, первые символы которых - #) с количеством встреч. Что можно сказать о них?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "zk4fygCUBw3l",
    "ExecuteTime": {
     "end_time": "2025-05-10T16:17:39.317303500Z",
     "start_time": "2025-05-10T16:17:39.274691900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dmitriy\\AppData\\Local\\Temp\\ipykernel_12104\\533891431.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  words_count_df_copy[words_count_df[\"Word\"].str[0] == '#'].head(10)\n"
     ]
    },
    {
     "data": {
      "text/plain": "              Word  Count\n13    #coronavirus  10211\n60        #COVID19   2621\n75       #Covid_19   2126\n90    #Coronavirus   1806\n116     #COVID2019   1341\n159   #toiletpaper    944\n175       #covid19    829\n186         #COVID    775\n246  #CoronaCrisis    599\n284   #CoronaVirus    525",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13</th>\n      <td>#coronavirus</td>\n      <td>10211</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>#COVID19</td>\n      <td>2621</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>#Covid_19</td>\n      <td>2126</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>#Coronavirus</td>\n      <td>1806</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>#COVID2019</td>\n      <td>1341</td>\n    </tr>\n    <tr>\n      <th>159</th>\n      <td>#toiletpaper</td>\n      <td>944</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>#covid19</td>\n      <td>829</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>#COVID</td>\n      <td>775</td>\n    </tr>\n    <tr>\n      <th>246</th>\n      <td>#CoronaCrisis</td>\n      <td>599</td>\n    </tr>\n    <tr>\n      <th>284</th>\n      <td>#CoronaVirus</td>\n      <td>525</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count_df_copy[words_count_df[\"Word\"].str[0] == '#'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6NeNWBkDxM7"
   },
   "source": [
    "**Ответ:** О хештегах можно сказать следующее: все хештеги, очевидно, упоминают эпидемию. Один забавный хештег смог затесаться в этот топ - #toiletpaper, все мы знаем, почему :))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLYBg7caD5GA"
   },
   "source": [
    "То же самое проделайте для ссылок на сайт https://t.co Сравнима ли популярность ссылок с популярностью хештегов? Будет ли информация о ссылке на конкретную страницу полезна?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "MXbm1oeaCK9S",
    "ExecuteTime": {
     "end_time": "2025-05-10T19:19:42.774241100Z",
     "start_time": "2025-05-10T19:19:42.550393300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Word  Count\n",
      "11014  https://t.co/oXA7SWtoNd      6\n",
      "12562  https://t.co/G63RP042HO      5\n",
      "13125  https://t.co/R7sAGojsjg      4\n",
      "13354  https://t.co/WrLHYzIzAA      4\n",
      "13709  https://t.co/ymsEmlVTTd      4\n",
      "13993  https://t.co/3kFUIOJXEp      4\n",
      "14604  https://t.co/OI39zSAnQ8      4\n",
      "14916  https://t.co/6yVYKIAb2c      4\n",
      "14917  https://t.co/xPcm2Xkj4O      4\n",
      "14951  https://t.co/gu6B4XpqP4      4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dmitriy\\AppData\\Local\\Temp\\ipykernel_12104\\2305966469.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(words_count_df_copy[words_count_df[\"Word\"].str.startswith('https://t.co')].head(10))\n"
     ]
    }
   ],
   "source": [
    "print(words_count_df_copy[words_count_df[\"Word\"].str.startswith('https://t.co')].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "at6lRYZ8A07N"
   },
   "source": [
    "**Ответ:** Так как топ весьма маленький (мало повторений) и по ссылкам не всегда понятна окраска сообщения, в котором была вставлена ссылка, то информация, которую она несёт, в том виде, в котором мы видим сейчас, невелика."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOGdUU1kBU1D"
   },
   "source": [
    "Используем опыт предыдущих экспериментов и напишем собственный токенайзер, улучшив TweetTokenizer. Функция tokenize должна:\n",
    "\n",
    "\n",
    "\n",
    "*   Привести текст в нижний регистр\n",
    "*   Применить TweetTokenizer для  выделения токенов\n",
    "*   Удалить стоп-слова, пунктуацию, токены из одного символа с позицией в таблице Unicode 128 и более,  ссылки на t.co\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "ctEsB6xkFrrK",
    "ExecuteTime": {
     "end_time": "2025-05-10T20:59:11.568680100Z",
     "start_time": "2025-05-10T20:59:11.530283800Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "    tokenizer = TweetTokenizer()\n",
    "\n",
    "    words = tokenizer.tokenize(text.lower())\n",
    "\n",
    "    words = Counter(words)\n",
    "    words_count = words.most_common()\n",
    "    words_count_df = pd.DataFrame(words_count, columns=['Word', 'Count'])\n",
    "\n",
    "    words_count_df_copy = words_count_df[~words_count_df[\"Word\"].isin(punctuation_list) & ~words_count_df[\"Word\"].isin(stops)]\n",
    "\n",
    "    words_count_df_copy = words_count_df_copy[\n",
    "        (words_count_df_copy[\"Word\"].str.len() > 1) |\n",
    "        (words_count_df_copy[\"Word\"].apply(\n",
    "            lambda x: ord(x) if len(x) == 1 else 0\n",
    "        ) <= 127)\n",
    "        ]\n",
    "    \n",
    "    words_count_df_copy = words_count_df_copy[~words_count_df[\"Word\"].str.startswith('https://t.co')]\n",
    "    \n",
    "    return words_count_df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XwbgtYkJGYym",
    "outputId": "5808765b-3448-45e6-ccc1-7cd65f6371ef",
    "ExecuteTime": {
     "end_time": "2025-05-10T20:59:13.272798500Z",
     "start_time": "2025-05-10T20:59:13.227291700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dmitriy\\AppData\\Local\\Temp\\ipykernel_12104\\697399648.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  words_count_df_copy = words_count_df_copy[~words_count_df[\"Word\"].str.startswith('https://t.co')]\n"
     ]
    },
    {
     "data": {
      "text/plain": "            Word  Count\n4         sample      1\n5           text      1\n6   @sample_text      1\n10   #sampletext      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>sample</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>text</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>@sample_text</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>#sampletext</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tokenizer('This is sample text!!!! @Sample_text I, \\x92\\x92 https://t.co/sample  #sampletext')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wURVABmXHk97"
   },
   "source": [
    "## Задание 3 Векторизация текстов (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H44iXkoHIQfN"
   },
   "source": [
    "Обучите CountVectorizer с использованием custom_tokenizer в качестве токенайзера. Как размер полученного словаря соотносится с размером изначального словаря из начала задания 2?"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer  # -- YOUR CODE HERE --\n",
    "\n",
    "print(len(cv.vocabulary_))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHn_limQl3BI",
    "outputId": "8e9c1826-319f-4376-f06e-c30c2eb82648"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "45308\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsfmaSGoItUm"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lm6UHNmqKZT0"
   },
   "source": [
    "Посмотрим на какой-нибудь конкретный твитт:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJVjjfqOJh8m"
   },
   "outputs": [],
   "source": [
    "ind = 9023\n",
    "train.iloc[ind]['OriginalTweet'], train.iloc[ind]['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBMIHBI5KdaS"
   },
   "source": [
    "Автор твитта не доволен ситуацией с едой во Франции и текст имеет резко негативную окраску.\n",
    "\n",
    "Примените обученный CountVectorizer для векторизации данного текста, и попытайтесь определить самый важный токен и самый неважный токен (токен, компонента которого в векторе максимальна/минимальна, без учета 0). Хорошо ли они определились, почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7NcAllaEKsJj"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpEsl1k_NF4T"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4DsEQpLO3J6"
   },
   "source": [
    "Теперь примените TfidfVectorizer и  определите самый важный/неважный токены. Хорошо ли определились, почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uSNzdK3ENGB3"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYao_UhqQADm"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGRJPqfWSesQ"
   },
   "source": [
    "Найдите какой-нибудь положительно окрашенный твитт, где TfidfVectorizer хорошо (полезно для определения окраски) выделяет важный токен, поясните пример.\n",
    "\n",
    "*Подсказка:* явно положительные твитты можно искать при помощи положительных слов (good, great, amazing и т. д.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRbQ2CHiSuJI",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "outputId": "c4b34a7d-1076-4e1e-ad5c-9466fd2097c2"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [UserName, ScreenName, Location, TweetAt, OriginalTweet, Sentiment]\n",
       "Index: []"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-7ca73bc8-3352-450a-ab2b-98a4d5aecc6f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ca73bc8-3352-450a-ab2b-98a4d5aecc6f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-7ca73bc8-3352-450a-ab2b-98a4d5aecc6f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-7ca73bc8-3352-450a-ab2b-98a4d5aecc6f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "repr_error": "Out of range float values are not JSON compliant: nan"
      }
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "train[train['OriginalTweet'].apply(lambda x: 'your_good_word_here' in x) & (train['Sentiment'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# -- YOUR CODE HERE --"
   ],
   "metadata": {
    "id": "jSjbKPCWk87K"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTv9ST2_U6NA"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVEuZm8BHms6"
   },
   "source": [
    "## Задание 4 Обучение первых моделей (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JADkO3sfXdOG"
   },
   "source": [
    "Примените оба векторайзера для получения матриц с признаками текстов.  Выделите целевую переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DguoiXhCX2oN"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FX1KSOfYSx4"
   },
   "source": [
    "Обучите логистическую регрессию на векторах из обоих векторайзеров. Посчитайте долю правильных ответов на обучающих и тестовых данных. Какой векторайзер показал лучший результат? Что можно сказать о моделях?\n",
    "\n",
    "Используйте `sparse` матрицы (после векторизации), не превращайте их в `numpy.ndarray` или `pd.DataFrame` - может не хватить памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Tb3eh8UXJ6v"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8y_wO7rCmv7K"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSOR1i3mjrys"
   },
   "source": [
    "## Задание 5 Стемминг (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6ONBWNPjuq-"
   },
   "source": [
    "Для уменьшения словаря можно использовать стемминг.\n",
    "\n",
    "Модифицируйте написанный токенайзер, добавив в него стемминг с использованием SnowballStemmer. Обучите Count- и Tfidf- векторайзеры. Как изменился размер словаря?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVfA2-iMkQBb"
   },
   "outputs": [],
   "source": [
    "def custom_stem_tokenizer(text):\n",
    "    # -- YOUR CODE HERE --\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QmrjYtqnlPd",
    "outputId": "cd91291d-9676-4611-9fc4-28afaed58963"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['sampl', 'text', '@sample_text', '#sampletext', 'ad', 'word', 'check', 'stem']"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "custom_stem_tokenizer(\n",
    "    'This is sample text!!!! @Sample_text I, \\x92\\x92 https://t.co/sample  #sampletext adding more words to check stemming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zAvUTmaplzOS",
    "outputId": "566207fe-183b-4ed6-d333-f86f0cc9ae38"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "36652\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer  # -- YOUR CODE HERE --\n",
    "\n",
    "print(len(cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oyzs5TaAoHP6"
   },
   "source": [
    "**Ответ** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OkncHI8oRmd"
   },
   "source": [
    "Обучите логистическую регрессию с использованием обоих векторайзеров. Изменилось ли качество? Есть ли смысл применять стемминг?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykZJPphEoZ5W"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCRlrODro0h8"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYWGQNEDqLC-"
   },
   "source": [
    "## Задание  6 Работа с частотами (1.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Hq-tl5mqUSn"
   },
   "source": [
    "Еще один способ уменьшить количество признаков - это использовать параметры min_df и max_df при построении векторайзера  эти параметры помогают ограничить требуемую частоту встречаемости токена в документах.\n",
    "\n",
    "По умолчанию берутся все токены, которые встретились хотя бы один раз.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1SiD4DE3WZ2"
   },
   "source": [
    "Подберите max_df такой, что размер словаря будет 36651 (на 1 меньше, чем было). Почему параметр получился такой большой/маленький?"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "cv_df = CountVectorizer(tokenizer=custom_stem_tokenizer,\n",
    "                        max_df=  # -- YOUR CODE HERE --\n",
    "                        ).fit(\n",
    "    # -- YOUR CODE HERE --\n",
    ")\n",
    "print(len(cv_df.vocabulary_))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3YLb8PViExb",
    "outputId": "b6d67654-d232-4e11-a5ca-6f2145053e98"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "36651\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# -- YOUR CODE HERE --"
   ],
   "metadata": {
    "id": "tyEpkJUkjnuK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdZYoGZR4UsA"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gRIUaB1u32f"
   },
   "source": [
    "Подберите min_df (используйте дефолтное значение max_df) в CountVectorizer таким образом, чтобы размер словаря был 3700 токенов (при использовании токенайзера со стеммингом), а качество осталось таким же, как и было. Что можно сказать о результатах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSnMJkn9XmsT",
    "outputId": "e0d8eb21-e5d7-46b4-e1d1-4b1ae220e9a0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3700\n"
     ]
    }
   ],
   "source": [
    "cv_df = CountVectorizer(tokenizer=custom_stem_tokenizer,\n",
    "                        min_df=  # -- YOUR CODE HERE --\n",
    "                        ).fit(\n",
    "    # -- YOUR CODE HERE --\n",
    ")\n",
    "print(len(cv_df.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# -- YOUR CODE HERE --"
   ],
   "metadata": {
    "id": "mvMDwpdfjm8Y"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fGYpUIZx0fk"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "В предыдущих заданиях признаки не скалировались. Отскалируйте данные (при словаре размера 3.7 тысяч, векторизованные CountVectorizer), обучите логистическую регрессию, посмотрите качество и выведите `barplot`, содержащий по 10 токенов, с наибольшим по модулю положительными/отрицательными весами. Что можно сказать об этих токенах?"
   ],
   "metadata": {
    "id": "Gx_h_-inKbBl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# -- YOUR CODE HERE --"
   ],
   "metadata": {
    "id": "KBATXJX6LG9q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ],
   "metadata": {
    "id": "ThcEfzY1LHET"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktJVOdrIHq7B"
   },
   "source": [
    "## Задание 7 Другие признаки (1.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yt3jRCZ2H0Og"
   },
   "source": [
    "Мы были сконцентрированы на работе с текстами твиттов и не использовали другие признаки - имена пользователя, дату и местоположение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52wjewCCo_di"
   },
   "source": [
    "Изучите признаки UserName и ScreenName. полезны ли они? Если полезны, то закодируйте их, добавьте к матрице с отскалированными признаками, обучите логистическую регрессию, замерьте качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63thouYZptj6"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8_qR-gnpT3a"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ythEcFSkt7y3"
   },
   "source": [
    "Изучите признак TweetAt в обучающей выборке: преобразуйте его к типу datetime и нарисуйте его гистограмму с разделением по цвету на основе целевой переменной. Полезен ли он? Если полезен, то закодируйте его, добавьте к матрице с отскалированными признаками, обучите логистическую регрессию, замерьте качество."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# -- YOUR CODE HERE --"
   ],
   "metadata": {
    "id": "Lxb_k0JLirNv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IdLBdpQxM-G"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Поработайте с признаком Location в обучающей выборке. Сколько уникальных значений?"
   ],
   "metadata": {
    "id": "r2JtRPhNP6qx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# -- YOUR CODE HERE --"
   ],
   "metadata": {
    "id": "xYQZQ1FRNpoe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Постройте гистограмму топ-10 по популярности местоположений (исключая Unknown)"
   ],
   "metadata": {
    "id": "6k4JwpRTQISa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# -- YOUR CODE HERE --"
   ],
   "metadata": {
    "id": "J91YkhegJ0mz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видно, что многие местоположения включают в себя более точное название места, чем другие (Например, у некоторых стоит London, UK; а у некоторых просто UK или United Kingdom).\n",
    "\n",
    "Создайте новый признак WiderLocation, который содержит самое широкое местоположение (например, из London, UK должно получиться UK). Сколько уникальных категорий теперь? Постройте аналогичную гистограмму."
   ],
   "metadata": {
    "id": "ZOsv3lODTfYB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# -- YOUR CODE HERE --"
   ],
   "metadata": {
    "id": "mSkow6acOMyD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Закодируйте признак WiderLocation с помощью OHE таким образом, чтобы создались только столбцы для местоположений, которые встречаются более одного раза. Сколько таких значений?\n"
   ],
   "metadata": {
    "id": "cgyWrD2eVfff"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# -- YOUR CODE HERE --"
   ],
   "metadata": {
    "id": "SeJBfBWgPvg_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Добавьте этот признак к матрице отскалированных текстовых признаков, обучите логистическую регрессию, замерьте качество. Как оно изменилось? Оказался ли признак полезным?\n",
    "\n",
    "\n",
    "*Подсказка:* используйте параметр `categories` в энкодере."
   ],
   "metadata": {
    "id": "ZyMX5kZuimPK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# -- YOUR CODE HERE --"
   ],
   "metadata": {
    "id": "EO1jNPeeim7A"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ],
   "metadata": {
    "id": "7dHsGlDRYUQt"
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
